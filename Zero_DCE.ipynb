{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Model Definition"
      ],
      "metadata": {
        "id": "gY2ATVDupYEn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVLJ17v9omQE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "#import pytorch_colors as colors\n",
        "import numpy as np\n",
        "\n",
        "class enhance_net_nopool(nn.Module):\n",
        "\n",
        "\tdef __init__(self):\n",
        "\t\tsuper(enhance_net_nopool, self).__init__()\n",
        "\n",
        "\t\tself.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "\t\tnumber_f = 32\n",
        "\t\tself.e_conv1 = nn.Conv2d(3,number_f,3,1,1,bias=True)\n",
        "\t\tself.e_conv2 = nn.Conv2d(number_f,number_f,3,1,1,bias=True)\n",
        "\t\tself.e_conv3 = nn.Conv2d(number_f,number_f,3,1,1,bias=True)\n",
        "\t\tself.e_conv4 = nn.Conv2d(number_f,number_f,3,1,1,bias=True)\n",
        "\t\tself.e_conv5 = nn.Conv2d(number_f*2,number_f,3,1,1,bias=True)\n",
        "\t\tself.e_conv6 = nn.Conv2d(number_f*2,number_f,3,1,1,bias=True)\n",
        "\t\tself.e_conv7 = nn.Conv2d(number_f*2,24,3,1,1,bias=True)\n",
        "\n",
        "\t\tself.maxpool = nn.MaxPool2d(2, stride=2, return_indices=False, ceil_mode=False)\n",
        "\t\tself.upsample = nn.UpsamplingBilinear2d(scale_factor=2)\n",
        "\n",
        "\n",
        "\n",
        "\tdef forward(self, x):\n",
        "\n",
        "\t\tx1 = self.relu(self.e_conv1(x))\n",
        "\t\t# p1 = self.maxpool(x1)\n",
        "\t\tx2 = self.relu(self.e_conv2(x1))\n",
        "\t\t# p2 = self.maxpool(x2)\n",
        "\t\tx3 = self.relu(self.e_conv3(x2))\n",
        "\t\t# p3 = self.maxpool(x3)\n",
        "\t\tx4 = self.relu(self.e_conv4(x3))\n",
        "\n",
        "\t\tx5 = self.relu(self.e_conv5(torch.cat([x3,x4],1)))\n",
        "\t\t# x5 = self.upsample(x5)\n",
        "\t\tx6 = self.relu(self.e_conv6(torch.cat([x2,x5],1)))\n",
        "\n",
        "\t\tx_r = F.tanh(self.e_conv7(torch.cat([x1,x6],1)))\n",
        "\t\tr1,r2,r3,r4,r5,r6,r7,r8 = torch.split(x_r, 3, dim=1)\n",
        "\n",
        "\n",
        "\t\tx = x + r1*(torch.pow(x,2)-x)\n",
        "\t\tx = x + r2*(torch.pow(x,2)-x)\n",
        "\t\tx = x + r3*(torch.pow(x,2)-x)\n",
        "\t\tenhance_image_1 = x + r4*(torch.pow(x,2)-x)\n",
        "\t\tx = enhance_image_1 + r5*(torch.pow(enhance_image_1,2)-enhance_image_1)\n",
        "\t\tx = x + r6*(torch.pow(x,2)-x)\n",
        "\t\tx = x + r7*(torch.pow(x,2)-x)\n",
        "\t\tenhance_image = x + r8*(torch.pow(x,2)-x)\n",
        "\t\tr = torch.cat([r1,r2,r3,r4,r5,r6,r7,r8],1)\n",
        "\t\treturn enhance_image_1,enhance_image,r"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataloader func"
      ],
      "metadata": {
        "id": "OLEAA-qZqd0w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import glob\n",
        "import random\n",
        "import cv2\n",
        "\n",
        "random.seed(1143)\n",
        "\n",
        "\n",
        "def populate_train_list(lowlight_images_path):\n",
        "\n",
        "  print(lowlight_images_path)\n",
        "  image_list_lowlight = glob.glob(lowlight_images_path + \"*.JPG\")\n",
        "  train_list = image_list_lowlight\n",
        "  random.shuffle(train_list)\n",
        "  return train_list\n",
        "\n",
        "\n",
        "\n",
        "class lowlight_loader(data.Dataset):\n",
        "\n",
        "\tdef __init__(self, lowlight_images_path):\n",
        "\n",
        "\t\tself.train_list = populate_train_list(lowlight_images_path)\n",
        "\t\tself.size = 256\n",
        "\n",
        "\t\tself.data_list = self.train_list\n",
        "\t\tprint(\"Total training examples:\", len(self.train_list))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\tdef __getitem__(self, index):\n",
        "\n",
        "\t\tdata_lowlight_path = self.data_list[index]\n",
        "\n",
        "\t\tdata_lowlight = Image.open(data_lowlight_path)\n",
        "\n",
        "\t\tdata_lowlight = data_lowlight.resize((self.size,self.size), Image.ANTIALIAS)\n",
        "\n",
        "\t\tdata_lowlight = (np.asarray(data_lowlight)/255.0)\n",
        "\t\tdata_lowlight = torch.from_numpy(data_lowlight).float()\n",
        "\n",
        "\t\treturn data_lowlight.permute(2,0,1)\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\treturn len(self.data_list)"
      ],
      "metadata": {
        "id": "zLoXyfTEqNJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Many losses"
      ],
      "metadata": {
        "id": "fhnwycVdqgTA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "from torchvision.models.vgg import vgg16\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class L_color(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(L_color, self).__init__()\n",
        "\n",
        "    def forward(self, x ):\n",
        "\n",
        "        b,c,h,w = x.shape\n",
        "\n",
        "        mean_rgb = torch.mean(x,[2,3],keepdim=True)\n",
        "        mr,mg, mb = torch.split(mean_rgb, 1, dim=1)\n",
        "        Drg = torch.pow(mr-mg,2)\n",
        "        Drb = torch.pow(mr-mb,2)\n",
        "        Dgb = torch.pow(mb-mg,2)\n",
        "        k = torch.pow(torch.pow(Drg,2) + torch.pow(Drb,2) + torch.pow(Dgb,2),0.5)\n",
        "\n",
        "\n",
        "        return k\n",
        "\n",
        "\n",
        "class L_spa(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(L_spa, self).__init__()\n",
        "        # print(1)kernel = torch.FloatTensor(kernel).unsqueeze(0).unsqueeze(0)\n",
        "        kernel_left = torch.FloatTensor( [[0,0,0],[-1,1,0],[0,0,0]]).cuda().unsqueeze(0).unsqueeze(0)\n",
        "        kernel_right = torch.FloatTensor( [[0,0,0],[0,1,-1],[0,0,0]]).cuda().unsqueeze(0).unsqueeze(0)\n",
        "        kernel_up = torch.FloatTensor( [[0,-1,0],[0,1, 0 ],[0,0,0]]).cuda().unsqueeze(0).unsqueeze(0)\n",
        "        kernel_down = torch.FloatTensor( [[0,0,0],[0,1, 0],[0,-1,0]]).cuda().unsqueeze(0).unsqueeze(0)\n",
        "        self.weight_left = nn.Parameter(data=kernel_left, requires_grad=False)\n",
        "        self.weight_right = nn.Parameter(data=kernel_right, requires_grad=False)\n",
        "        self.weight_up = nn.Parameter(data=kernel_up, requires_grad=False)\n",
        "        self.weight_down = nn.Parameter(data=kernel_down, requires_grad=False)\n",
        "        self.pool = nn.AvgPool2d(4)\n",
        "    def forward(self, org , enhance ):\n",
        "        b,c,h,w = org.shape\n",
        "\n",
        "        org_mean = torch.mean(org,1,keepdim=True)\n",
        "        enhance_mean = torch.mean(enhance,1,keepdim=True)\n",
        "\n",
        "        org_pool =  self.pool(org_mean)\n",
        "        enhance_pool = self.pool(enhance_mean)\n",
        "\n",
        "        weight_diff =torch.max(torch.FloatTensor([1]).cuda() + 10000*torch.min(org_pool - torch.FloatTensor([0.3]).cuda(),torch.FloatTensor([0]).cuda()),torch.FloatTensor([0.5]).cuda())\n",
        "        E_1 = torch.mul(torch.sign(enhance_pool - torch.FloatTensor([0.5]).cuda()) ,enhance_pool-org_pool)\n",
        "\n",
        "\n",
        "        D_org_letf = F.conv2d(org_pool , self.weight_left, padding=1)\n",
        "        D_org_right = F.conv2d(org_pool , self.weight_right, padding=1)\n",
        "        D_org_up = F.conv2d(org_pool , self.weight_up, padding=1)\n",
        "        D_org_down = F.conv2d(org_pool , self.weight_down, padding=1)\n",
        "\n",
        "        D_enhance_letf = F.conv2d(enhance_pool , self.weight_left, padding=1)\n",
        "        D_enhance_right = F.conv2d(enhance_pool , self.weight_right, padding=1)\n",
        "        D_enhance_up = F.conv2d(enhance_pool , self.weight_up, padding=1)\n",
        "        D_enhance_down = F.conv2d(enhance_pool , self.weight_down, padding=1)\n",
        "\n",
        "        D_left = torch.pow(D_org_letf - D_enhance_letf,2)\n",
        "        D_right = torch.pow(D_org_right - D_enhance_right,2)\n",
        "        D_up = torch.pow(D_org_up - D_enhance_up,2)\n",
        "        D_down = torch.pow(D_org_down - D_enhance_down,2)\n",
        "        E = (D_left + D_right + D_up +D_down)\n",
        "        # E = 25*(D_left + D_right + D_up +D_down)\n",
        "\n",
        "        return E\n",
        "class L_exp(nn.Module):\n",
        "\n",
        "    def __init__(self,patch_size,mean_val):\n",
        "        super(L_exp, self).__init__()\n",
        "        # print(1)\n",
        "        self.pool = nn.AvgPool2d(patch_size)\n",
        "        self.mean_val = mean_val\n",
        "    def forward(self, x ):\n",
        "\n",
        "        b,c,h,w = x.shape\n",
        "        x = torch.mean(x,1,keepdim=True)\n",
        "        mean = self.pool(x)\n",
        "\n",
        "        d = torch.mean(torch.pow(mean- torch.FloatTensor([self.mean_val] ).cuda(),2))\n",
        "        return d\n",
        "\n",
        "class L_TV(nn.Module):\n",
        "    def __init__(self,TVLoss_weight=1):\n",
        "        super(L_TV,self).__init__()\n",
        "        self.TVLoss_weight = TVLoss_weight\n",
        "\n",
        "    def forward(self,x):\n",
        "        batch_size = x.size()[0]\n",
        "        h_x = x.size()[2]\n",
        "        w_x = x.size()[3]\n",
        "        count_h =  (x.size()[2]-1) * x.size()[3]\n",
        "        count_w = x.size()[2] * (x.size()[3] - 1)\n",
        "        h_tv = torch.pow((x[:,:,1:,:]-x[:,:,:h_x-1,:]),2).sum()\n",
        "        w_tv = torch.pow((x[:,:,:,1:]-x[:,:,:,:w_x-1]),2).sum()\n",
        "        return self.TVLoss_weight*2*(h_tv/count_h+w_tv/count_w)/batch_size\n",
        "class Sa_Loss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Sa_Loss, self).__init__()\n",
        "        # print(1)\n",
        "    def forward(self, x ):\n",
        "        # self.grad = np.ones(x.shape,dtype=np.float32)\n",
        "        b,c,h,w = x.shape\n",
        "        # x_de = x.cpu().detach().numpy()\n",
        "        r,g,b = torch.split(x , 1, dim=1)\n",
        "        mean_rgb = torch.mean(x,[2,3],keepdim=True)\n",
        "        mr,mg, mb = torch.split(mean_rgb, 1, dim=1)\n",
        "        Dr = r-mr\n",
        "        Dg = g-mg\n",
        "        Db = b-mb\n",
        "        k =torch.pow( torch.pow(Dr,2) + torch.pow(Db,2) + torch.pow(Dg,2),0.5)\n",
        "        # print(k)\n",
        "\n",
        "\n",
        "        k = torch.mean(k)\n",
        "        return k\n",
        "\n",
        "class perception_loss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(perception_loss, self).__init__()\n",
        "        features = vgg16(pretrained=True).features\n",
        "        self.to_relu_1_2 = nn.Sequential()\n",
        "        self.to_relu_2_2 = nn.Sequential()\n",
        "        self.to_relu_3_3 = nn.Sequential()\n",
        "        self.to_relu_4_3 = nn.Sequential()\n",
        "\n",
        "        for x in range(4):\n",
        "            self.to_relu_1_2.add_module(str(x), features[x])\n",
        "        for x in range(4, 9):\n",
        "            self.to_relu_2_2.add_module(str(x), features[x])\n",
        "        for x in range(9, 16):\n",
        "            self.to_relu_3_3.add_module(str(x), features[x])\n",
        "        for x in range(16, 23):\n",
        "            self.to_relu_4_3.add_module(str(x), features[x])\n",
        "\n",
        "        # don't need the gradients, just want the features\n",
        "        for param in self.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.to_relu_1_2(x)\n",
        "        h_relu_1_2 = h\n",
        "        h = self.to_relu_2_2(h)\n",
        "        h_relu_2_2 = h\n",
        "        h = self.to_relu_3_3(h)\n",
        "        h_relu_3_3 = h\n",
        "        h = self.to_relu_4_3(h)\n",
        "        h_relu_4_3 = h\n",
        "        # out = (h_relu_1_2, h_relu_2_2, h_relu_3_3, h_relu_4_3)\n",
        "        return h_relu_4_3"
      ],
      "metadata": {
        "id": "fyil-wscqisq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Unpacking dataset"
      ],
      "metadata": {
        "id": "pYz9QZ29tFI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile('drive/MyDrive/data/dataset.zip') as fh:\n",
        "  fh.extractall()"
      ],
      "metadata": {
        "id": "HwqM1uVHtIHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! mv ./dataset/* ./data/train_data/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksDIg0Bvta-H",
        "outputId": "21c774ee-3c56-424f-f8f7-fc23763c507f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: target './data/train_data/' is not a directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Main cell"
      ],
      "metadata": {
        "id": "tSOYHTCTqv5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import namedtuple\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim\n",
        "import os\n",
        "import sys\n",
        "import argparse\n",
        "import time\n",
        "import numpy as np\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        m.weight.data.normal_(0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        m.weight.data.normal_(1.0, 0.02)\n",
        "        m.bias.data.fill_(0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def train(config):\n",
        "    os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
        "    DCE_net = enhance_net_nopool().cuda()\n",
        "    DCE_net.apply(weights_init)\n",
        "    if config.load_pretrain == True:\n",
        "        DCE_net.load_state_dict(torch.load(config.pretrain_dir))\n",
        "\n",
        "    train_dataset = lowlight_loader(config.lowlight_images_path)\n",
        "    print(train_dataset)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=config.train_batch_size, shuffle=True, num_workers=config.num_workers, pin_memory=True)\n",
        "\n",
        "\n",
        "\n",
        "    l_color = L_color()\n",
        "    l_spa = L_spa()\n",
        "\n",
        "    l_exp = L_exp(16,0.6)\n",
        "    l_TV = L_TV()\n",
        "\n",
        "\n",
        "    optimizer = torch.optim.Adam(DCE_net.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
        "\n",
        "    DCE_net.train()\n",
        "\n",
        "    for epoch in range(config.num_epochs):\n",
        "      for iteration, img_lowlight in enumerate(train_loader):\n",
        "\n",
        "        img_lowlight = img_lowlight.cuda()\n",
        "\n",
        "        enhanced_image_1,enhanced_image,A  = DCE_net(img_lowlight)\n",
        "\n",
        "        Loss_TV = 200*l_TV(A)\n",
        "\n",
        "        loss_spa = torch.mean(l_spa(enhanced_image, img_lowlight))\n",
        "\n",
        "        loss_col = 5*torch.mean(l_color(enhanced_image))\n",
        "\n",
        "        loss_exp = 10*torch.mean(l_exp(enhanced_image))\n",
        "\n",
        "\n",
        "        # best_loss\n",
        "        loss =  Loss_TV + loss_spa + loss_col + loss_exp\n",
        "        #\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm(DCE_net.parameters(),config.grad_clip_norm)\n",
        "        optimizer.step()\n",
        "\n",
        "        if ((iteration+1) % config.display_iter) == 0:\n",
        "          print(\"Loss at iteration\", iteration+1, \":\", loss.item())\n",
        "        if ((iteration+1) % config.snapshot_iter) == 0:\n",
        "\n",
        "          torch.save(DCE_net.state_dict(), config.snapshots_folder + \"Epoch\" + str(epoch) + '.pth')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "\t# parser = argparse.ArgumentParser()\n",
        "\n",
        "\t# # Input Parameters\n",
        "\t# parser.add_argument('--lowlight_images_path', type=str, default=\"data/train_data/\")\n",
        "\t# parser.add_argument('--lr', type=float, default=0.0001)\n",
        "\t# parser.add_argument('--weight_decay', type=float, default=0.0001)\n",
        "\t# parser.add_argument('--grad_clip_norm', type=float, default=0.1)\n",
        "\t# parser.add_argument('--num_epochs', type=int, default=200)\n",
        "\t# parser.add_argument('--train_batch_size', type=int, default=8)\n",
        "\t# parser.add_argument('--val_batch_size', type=int, default=4)\n",
        "\t# parser.add_argument('--num_workers', type=int, default=4)\n",
        "\t# parser.add_argument('--display_iter', type=int, default=10)\n",
        "\t# parser.add_argument('--snapshot_iter', type=int, default=10)\n",
        "\t# parser.add_argument('--snapshots_folder', type=str, default=\"snapshots/\")\n",
        "\t# parser.add_argument('--load_pretrain', type=bool, default= False)\n",
        "\t# parser.add_argument('--pretrain_dir', type=str, default= \"snapshots/Epoch99.pth\")\n",
        "\n",
        "\t# config = parser.parse_args()\n",
        "\n",
        "    if not os.path.exists('snapshots'):\n",
        "\t\t    os.mkdir('snapshots')\n",
        "    Config = namedtuple(typename='Config',\n",
        "                      field_names='lowlight_images_path lr weight_decay grad_clip_norm num_epochs train_batch_size val_batch_size num_workers display_iter snapshot_iter snapshots_folder load_pretrain pretrain_dir')\n",
        "    config = Config(lowlight_images_path='dataset/low/',\n",
        "                    lr=1e-4,\n",
        "                    weight_decay=1e-4,\n",
        "                    grad_clip_norm=0.1,\n",
        "                    num_epochs=10,\n",
        "                    train_batch_size=8,\n",
        "                    val_batch_size=4,\n",
        "                    num_workers=4,\n",
        "                    display_iter=10,\n",
        "                    snapshot_iter=10,\n",
        "                    snapshots_folder='snapshots',\n",
        "                    load_pretrain=False,\n",
        "                    pretrain_dir='snapshots/Epoch99.pth')\n",
        "\n",
        "    print(config.lowlight_images_path)\n",
        "    train(config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQ78XoYgqvX2",
        "outputId": "31ac460b-96e3-46ac-dcdc-70ed3857215a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset/low/\n",
            "dataset/low/\n",
            "Total training examples: 739\n",
            "<__main__.lowlight_loader object at 0x782dde3f6cb0>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-6fe4a8e0e63c>:45: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  data_lowlight = data_lowlight.resize((self.size,self.size), Image.ANTIALIAS)\n",
            "<ipython-input-36-6fe4a8e0e63c>:45: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  data_lowlight = data_lowlight.resize((self.size,self.size), Image.ANTIALIAS)\n",
            "<ipython-input-36-6fe4a8e0e63c>:45: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  data_lowlight = data_lowlight.resize((self.size,self.size), Image.ANTIALIAS)\n",
            "<ipython-input-36-6fe4a8e0e63c>:45: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  data_lowlight = data_lowlight.resize((self.size,self.size), Image.ANTIALIAS)\n",
            "<ipython-input-42-44e2295659d7>:75: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
            "  torch.nn.utils.clip_grad_norm(DCE_net.parameters(),config.grad_clip_norm)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss at iteration 10 : 2.838231086730957\n",
            "Loss at iteration 20 : 2.6426167488098145\n",
            "Loss at iteration 30 : 3.000356435775757\n",
            "Loss at iteration 40 : 2.610485315322876\n",
            "Loss at iteration 50 : 2.359203577041626\n",
            "Loss at iteration 60 : 1.9219133853912354\n",
            "Loss at iteration 70 : 2.1342687606811523\n",
            "Loss at iteration 80 : 1.9892079830169678\n",
            "Loss at iteration 90 : 2.0536866188049316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-6fe4a8e0e63c>:45: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  data_lowlight = data_lowlight.resize((self.size,self.size), Image.ANTIALIAS)\n",
            "<ipython-input-36-6fe4a8e0e63c>:45: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  data_lowlight = data_lowlight.resize((self.size,self.size), Image.ANTIALIAS)\n",
            "<ipython-input-36-6fe4a8e0e63c>:45: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  data_lowlight = data_lowlight.resize((self.size,self.size), Image.ANTIALIAS)\n",
            "<ipython-input-36-6fe4a8e0e63c>:45: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  data_lowlight = data_lowlight.resize((self.size,self.size), Image.ANTIALIAS)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss at iteration 10 : 1.8665355443954468\n",
            "Loss at iteration 20 : 1.9111285209655762\n",
            "Loss at iteration 30 : 0.9831662178039551\n",
            "Loss at iteration 40 : 1.2037456035614014\n",
            "Loss at iteration 50 : 1.2717481851577759\n",
            "Loss at iteration 60 : 0.8526502847671509\n",
            "Loss at iteration 70 : 0.9140684604644775\n",
            "Loss at iteration 80 : 0.9310120940208435\n",
            "Loss at iteration 90 : 0.7928346395492554\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-6fe4a8e0e63c>:45: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  data_lowlight = data_lowlight.resize((self.size,self.size), Image.ANTIALIAS)\n",
            "<ipython-input-36-6fe4a8e0e63c>:45: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  data_lowlight = data_lowlight.resize((self.size,self.size), Image.ANTIALIAS)\n",
            "<ipython-input-36-6fe4a8e0e63c>:45: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  data_lowlight = data_lowlight.resize((self.size,self.size), Image.ANTIALIAS)\n",
            "<ipython-input-36-6fe4a8e0e63c>:45: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  data_lowlight = data_lowlight.resize((self.size,self.size), Image.ANTIALIAS)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss at iteration 10 : 0.8503995537757874\n",
            "Loss at iteration 20 : 0.8684111833572388\n",
            "Loss at iteration 30 : 1.3968722820281982\n",
            "Loss at iteration 40 : 0.5895294547080994\n",
            "Loss at iteration 50 : 0.7322898507118225\n",
            "Loss at iteration 60 : 0.8424534201622009\n",
            "Loss at iteration 70 : 1.0184762477874756\n",
            "Loss at iteration 80 : 0.6766331195831299\n",
            "Loss at iteration 90 : 0.8297868967056274\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-6fe4a8e0e63c>:45: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  data_lowlight = data_lowlight.resize((self.size,self.size), Image.ANTIALIAS)\n",
            "<ipython-input-36-6fe4a8e0e63c>:45: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  data_lowlight = data_lowlight.resize((self.size,self.size), Image.ANTIALIAS)\n",
            "<ipython-input-36-6fe4a8e0e63c>:45: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  data_lowlight = data_lowlight.resize((self.size,self.size), Image.ANTIALIAS)\n",
            "<ipython-input-36-6fe4a8e0e63c>:45: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  data_lowlight = data_lowlight.resize((self.size,self.size), Image.ANTIALIAS)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss at iteration 10 : 0.9664385914802551\n",
            "Loss at iteration 20 : 1.360647439956665\n",
            "Loss at iteration 30 : 0.6319637298583984\n",
            "Loss at iteration 40 : 1.1071019172668457\n",
            "Loss at iteration 50 : 0.7230488061904907\n",
            "Loss at iteration 60 : 0.7805615663528442\n",
            "Loss at iteration 70 : 0.6183333396911621\n",
            "Loss at iteration 80 : 1.014220118522644\n",
            "Loss at iteration 90 : 0.818138599395752\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-6fe4a8e0e63c>:45: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  data_lowlight = data_lowlight.resize((self.size,self.size), Image.ANTIALIAS)\n",
            "<ipython-input-36-6fe4a8e0e63c>:45: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  data_lowlight = data_lowlight.resize((self.size,self.size), Image.ANTIALIAS)\n",
            "<ipython-input-36-6fe4a8e0e63c>:45: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  data_lowlight = data_lowlight.resize((self.size,self.size), Image.ANTIALIAS)\n",
            "<ipython-input-36-6fe4a8e0e63c>:45: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  data_lowlight = data_lowlight.resize((self.size,self.size), Image.ANTIALIAS)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss at iteration 10 : 1.0275758504867554\n",
            "Loss at iteration 20 : 0.748002290725708\n",
            "Loss at iteration 30 : 0.8631169199943542\n",
            "Loss at iteration 40 : 0.8054494857788086\n",
            "Loss at iteration 50 : 0.9308217763900757\n",
            "Loss at iteration 60 : 0.9209845066070557\n",
            "Loss at iteration 70 : 0.7389471530914307\n",
            "Loss at iteration 80 : 0.9044817686080933\n",
            "Loss at iteration 90 : 1.142937183380127\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-6fe4a8e0e63c>:45: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  data_lowlight = data_lowlight.resize((self.size,self.size), Image.ANTIALIAS)\n",
            "<ipython-input-36-6fe4a8e0e63c>:45: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  data_lowlight = data_lowlight.resize((self.size,self.size), Image.ANTIALIAS)\n",
            "<ipython-input-36-6fe4a8e0e63c>:45: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  data_lowlight = data_lowlight.resize((self.size,self.size), Image.ANTIALIAS)\n",
            "<ipython-input-36-6fe4a8e0e63c>:45: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  data_lowlight = data_lowlight.resize((self.size,self.size), Image.ANTIALIAS)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss at iteration 10 : 0.6785875558853149\n",
            "Loss at iteration 20 : 0.8135749101638794\n",
            "Loss at iteration 30 : 0.9307042360305786\n",
            "Loss at iteration 40 : 0.8323526382446289\n",
            "Loss at iteration 50 : 0.8005580902099609\n",
            "Loss at iteration 60 : 0.8524062633514404\n",
            "Loss at iteration 70 : 0.6912227869033813\n",
            "Loss at iteration 80 : 0.817693293094635\n",
            "Loss at iteration 90 : 0.6217324733734131\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-6fe4a8e0e63c>:45: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  data_lowlight = data_lowlight.resize((self.size,self.size), Image.ANTIALIAS)\n",
            "<ipython-input-36-6fe4a8e0e63c>:45: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  data_lowlight = data_lowlight.resize((self.size,self.size), Image.ANTIALIAS)\n",
            "<ipython-input-36-6fe4a8e0e63c>:45: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  data_lowlight = data_lowlight.resize((self.size,self.size), Image.ANTIALIAS)\n",
            "<ipython-input-36-6fe4a8e0e63c>:45: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  data_lowlight = data_lowlight.resize((self.size,self.size), Image.ANTIALIAS)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss at iteration 10 : 0.7488853931427002\n",
            "Loss at iteration 20 : 0.750346302986145\n",
            "Loss at iteration 30 : 1.1003437042236328\n",
            "Loss at iteration 40 : 0.7912396192550659\n",
            "Loss at iteration 50 : 0.7059059143066406\n",
            "Loss at iteration 60 : 0.8259745836257935\n",
            "Loss at iteration 70 : 0.6692497730255127\n",
            "Loss at iteration 80 : 0.6367825865745544\n",
            "Loss at iteration 90 : 1.0271201133728027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-6fe4a8e0e63c>:45: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  data_lowlight = data_lowlight.resize((self.size,self.size), Image.ANTIALIAS)\n",
            "<ipython-input-36-6fe4a8e0e63c>:45: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  data_lowlight = data_lowlight.resize((self.size,self.size), Image.ANTIALIAS)\n",
            "<ipython-input-36-6fe4a8e0e63c>:45: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  data_lowlight = data_lowlight.resize((self.size,self.size), Image.ANTIALIAS)\n",
            "<ipython-input-36-6fe4a8e0e63c>:45: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  data_lowlight = data_lowlight.resize((self.size,self.size), Image.ANTIALIAS)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss at iteration 10 : 0.789138913154602\n",
            "Loss at iteration 20 : 0.9202148914337158\n",
            "Loss at iteration 30 : 1.1560499668121338\n",
            "Loss at iteration 40 : 1.342419147491455\n",
            "Loss at iteration 50 : 0.7387574911117554\n",
            "Loss at iteration 60 : 0.951035737991333\n",
            "Loss at iteration 70 : 0.7774948477745056\n",
            "Loss at iteration 80 : 0.7299361228942871\n",
            "Loss at iteration 90 : 0.556025505065918\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-6fe4a8e0e63c>:45: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  data_lowlight = data_lowlight.resize((self.size,self.size), Image.ANTIALIAS)\n",
            "<ipython-input-36-6fe4a8e0e63c>:45: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  data_lowlight = data_lowlight.resize((self.size,self.size), Image.ANTIALIAS)\n",
            "<ipython-input-36-6fe4a8e0e63c>:45: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  data_lowlight = data_lowlight.resize((self.size,self.size), Image.ANTIALIAS)\n",
            "<ipython-input-36-6fe4a8e0e63c>:45: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  data_lowlight = data_lowlight.resize((self.size,self.size), Image.ANTIALIAS)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss at iteration 10 : 0.42378002405166626\n",
            "Loss at iteration 20 : 0.8534656763076782\n",
            "Loss at iteration 30 : 0.6332070827484131\n",
            "Loss at iteration 40 : 0.9819373488426208\n",
            "Loss at iteration 50 : 0.7927204370498657\n",
            "Loss at iteration 60 : 0.753942608833313\n",
            "Loss at iteration 70 : 0.7407373785972595\n",
            "Loss at iteration 80 : 1.221308708190918\n",
            "Loss at iteration 90 : 0.6613943576812744\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-6fe4a8e0e63c>:45: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  data_lowlight = data_lowlight.resize((self.size,self.size), Image.ANTIALIAS)\n",
            "<ipython-input-36-6fe4a8e0e63c>:45: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  data_lowlight = data_lowlight.resize((self.size,self.size), Image.ANTIALIAS)\n",
            "<ipython-input-36-6fe4a8e0e63c>:45: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  data_lowlight = data_lowlight.resize((self.size,self.size), Image.ANTIALIAS)\n",
            "<ipython-input-36-6fe4a8e0e63c>:45: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  data_lowlight = data_lowlight.resize((self.size,self.size), Image.ANTIALIAS)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss at iteration 10 : 1.2602710723876953\n",
            "Loss at iteration 20 : 0.856682538986206\n",
            "Loss at iteration 30 : 0.7644873261451721\n",
            "Loss at iteration 40 : 0.7333015203475952\n",
            "Loss at iteration 50 : 0.8697239756584167\n",
            "Loss at iteration 60 : 0.9214871525764465\n",
            "Loss at iteration 70 : 1.0226349830627441\n",
            "Loss at iteration 80 : 0.7942115068435669\n",
            "Loss at iteration 90 : 0.6833429336547852\n"
          ]
        }
      ]
    }
  ]
}